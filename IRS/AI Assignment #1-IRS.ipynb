{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 IRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\"/>\n",
    "<img src=\"2.png\"/>\n",
    "<img src=\"3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n",
    "unique_word_dict = {}      # unique_word_dict to store all the unique words appearence in files   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code starts here   \n",
    "dict_name = \"Files\"       #Please enter path name Files attached in zip folder\n",
    "for path in os.listdir(dict_name):\n",
    "    if os.path.isfile((os.path.join(dict_name, path))):\n",
    "        if(fnmatch.fnmatch(path,\"*.txt\")): # To only check files with .txt extension. To count other files remove this statement\n",
    "            files_dict[path] = file_count\n",
    "            file_count += 1\n",
    "#Your code ends here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words in files\n",
      "\n",
      "{'pen', 'is', 'my', 'book', 'this', 'interesting'}\n",
      "\n",
      "count of files  3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "print(\"unique words in files\\n\")\n",
    "for path in os.listdir(dict_name):\n",
    "    with open((os.path.join(dict_name, path)), 'r') as f:\n",
    "        for line in f: \n",
    "            for word in line.split():\n",
    "                unique_word_set.add(word)  \n",
    "print(unique_word_set)\n",
    "print(\"\\ncount of files \",file_count)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERM DOC MATRIX INITIALLY\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "dictionary of unique words\n",
      "{'pen': 0, 'is': 1, 'my': 2, 'book': 3, 'this': 4, 'interesting': 5}\n",
      "\n",
      "dictionary of files\n",
      "{'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "def setTodict(set1):\n",
    "    dict1 = {}\n",
    "    dict1=dict.fromkeys(set1,0)    # converting set into dictionary and storing 0 in all value\n",
    "    i = -1\n",
    "    for word in dict1:\n",
    "        i += 1\n",
    "        dict1[word] = i\n",
    "    return dict1 \n",
    "    \n",
    "print(\"TERM DOC MATRIX INITIALLY\")\n",
    "TERM_DOC_MATRIX = np.zeros((file_count,len(unique_word_set)))\n",
    "print(TERM_DOC_MATRIX)\n",
    "\n",
    "print(\"\\ndictionary of unique words\")       \n",
    "unique_word_dict = setTodict(unique_word_set)      #calling function that count all unique words appea      \n",
    "print(unique_word_dict)                \n",
    "\n",
    "print(\"\\ndictionary of files\")\n",
    "print(files_dict)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERM DOC MATRIX after filling\n",
      "[[0. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 1. 1. 0. 1.]]\n",
      "col vector(initially)\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "file = -1                  # to keep track of file number in TERM_DOC_MATRIX\n",
    "print(\"TERM DOC MATRIX after filling\")\n",
    "for path in os.listdir(dict_name):\n",
    "    with open((os.path.join(dict_name, path)), 'r') as f:\n",
    "        lst =[]\n",
    "        file+=1\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                lst.append(word) \n",
    "            count = -1                         # to keep track of word in TERM_DOC_MATRIX\n",
    "            for unique_word in unique_word_set:\n",
    "                count +=1\n",
    "                if unique_word in lst:\n",
    "                    TERM_DOC_MATRIX[file][count] = 1\n",
    "                else:\n",
    "                    TERM_DOC_MATRIX[file][count] = 0                \n",
    "print(TERM_DOC_MATRIX) \n",
    "print(\"col vector(initially)\")\n",
    "#Your code ends here            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col vector(initially)\n",
      "\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "print(\"col vector(initially)\\n\")\n",
    "col_vector = np.array([0 for word in unique_word_set]).reshape(len(unique_word_set),1)\n",
    "print(col_vector)          # To make column vector\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  this book is interesting\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exixts then increment the count of that word in word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col vector(after filling)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "print(\"col vector(after filling)\")\n",
    "i=0\n",
    "for word in query.split():\n",
    "    for unique_word in unique_word_set:\n",
    "        if word == unique_word:\n",
    "            i = list(unique_word_dict.keys()).index(word)   # store indexes of\n",
    "            col_vector[i] += 1\n",
    "        else:\n",
    "            continue\n",
    "print(col_vector)   \n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.]\n",
      " [2.]\n",
      " [3.]]\n",
      "\n",
      "Maximum in resultant is  3.0\n",
      "\n",
      "Index of maximum in resultant is  0\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "index = 0                     # to store index of max value in resultant vector\n",
    "resultant_vector = np.dot(TERM_DOC_MATRIX,col_vector)\n",
    "print(resultant_vector)\n",
    "#max_value = np.amax(resultant_vector)\n",
    "max_value = resultant_vector[0]\n",
    "for i in range(len(resultant_vector)):\n",
    "    if(resultant_vector[i] > max_value):\n",
    "        index = i\n",
    "        max_value = resultant_vector[i]\n",
    "        \n",
    "print(\"\\nMaximum in resultant is \",max_value[0])\n",
    "print(\"\\nIndex of maximum in resultant is \",index)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  f1.txt\n",
      "this is my book\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "file_no = index \n",
    "for key,value in files_dict.items():\n",
    "    if value == file_no:\n",
    "        file_name = key\n",
    "with open((os.path.join(dict_name, file_name)), 'r') as f:\n",
    "        contents = f.read()\n",
    "print(\"File: \",file_name)\n",
    "print(contents)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
